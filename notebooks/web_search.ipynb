{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_hackathon_wait.api.deep_research import web_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[search] Generating deeper search queries for \"What are the counterfactual explanations?\"\n",
      "[search] Starting 3 parallel searches for \"What are the counterfactual explanations?\"\n",
      "[search] Searching for \"What are counterfactual explanations in machine learning?\" - Goal: To define counterfactual explanations and understand their role in machine learning.\n",
      "[search] Searching for \"How are counterfactual explanations used in ethical AI?\" - Goal: To explore the application of counterfactual explanations in promoting fairness and transparency in AI systems.\n",
      "[search] Searching for \"What are the methods for generating counterfactual explanations?\" - Goal: To investigate the various techniques and algorithms used to create counterfactual explanations.\n",
      "[search] Found 15 new relevant results across 3 parallel queries\n",
      "[analyze] Analyzing findings and planning next steps\n",
      "[analyze] Analyzed findings\n",
      "[synthesis] Preparing final analysis\n",
      "[synthesis] Research completed\n"
     ]
    }
   ],
   "source": [
    "res = web_search(\"What are the counterfactual explanations?\", max_urls=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'data': {'finalAnalysis': '# Counterfactual Explanations in Machine Learning: Methods, Insights, and Challenges\\n\\nCounterfactual explanations have emerged as a powerful tool to open the “black box” of machine learning models. By identifying the minimal changes in input features needed to alter a model’s output, these explanations offer an intuitive, actionable, and human‐friendly view of the decision-making process. This report synthesizes contemporary research, implementation strategies, use cases, strengths, limitations, and ethical considerations gathered from multiple sources, including Christoph Molnar’s work on interpretable machine learning, industry perspectives from KPMG and Lumenova, along with recent academic contributions.\\n\\n---\\n\\n## 1. Introduction\\n\\nIn many real-world applications—from loan approvals to medical diagnoses—users seek to understand why an artificial intelligence (AI) system made a particular decision and what could be changed to obtain a different outcome. Counterfactual explanations answer the “what if” question by asking: “What would need to change in the input for the output to be different?” For example, if a credit application is rejected, a counterfactual may suggest that a small increase in income or a reduction in credit cards could lead to approval.\\n\\nThe idea originates from causal reasoning and philosophy (cf. David Lewis’s counterfactual logic) and has been translated into a practical tool for machine learning interpretability. Researchers and practitioners have developed both model-agnostic and model-specific methods to generate these explanations, enabling transparency without requiring access to a model’s internal structure.\\n\\n---\\n\\n## 2. Defining Counterfactual Explanations\\n\\nA counterfactual explanation can be summarized as follows:\\n\\n\\u2003\\u2003\"If X had not occurred (or had been slightly different), then Y would not have occurred (or would have been different).\"\\n\\nFor instance, “If your annual income had been \\\\$10,000 higher, your credit application would have been approved.” Here, the counterfactual identifies the smallest actionable changes in input features that would flip a model’s prediction to a desired outcome. Importantly, while this reasoning is intuitive and contrastive, it does not imply true causality unless supported by an underlying causal model.\\n\\n---\\n\\n## 3. Methods for Generating Counterfactual Explanations\\n\\nResearchers have proposed several approaches to generate counterfactuals. Two prominent methods are:\\n\\n### 3.1. The Approach by Wachter et al.\\n\\nWachter, Mittelstadt, and Russell (2018) formulate counterfactual search as an optimization task. They propose minimizing a loss function with two key components:\\n\\n\\u2003• A term that quantifies the gap between the model’s prediction for the counterfactual instance and the desired output (often measured as a squared distance).\\n\\n\\u2003• A term that measures the dissimilarity between the counterfactual instance and the original instance, commonly using a weighted Manhattan (L₁) distance scaled by the inverse median absolute deviation (MAD).\\n\\nThe loss function is given by:\\n\\n\\u2003\\u2003L(x, x′, y′, λ) = λ · (f(x′) − y′)² + d(x, x′)\\n\\nwhere λ is a balancing parameter between fidelity (matching the desired outcome) and closeness (minimal deviations in feature values). One practical workflow involves selecting an instance, sampling a candidate counterfactual, and iteratively optimizing the loss while increasing λ until the prediction is sufficiently close to the target value.  \\n  \\n**Advantages:**  \\n\\u2003– Conceptual simplicity and direct interpretability.  \\n\\u2003– Model-agnostic: requires only inputs and outputs (useful when internal model structure is inaccessible).  \\n\\n**Limitations:**  \\n\\u2003– Typically considers only prediction accuracy and similarity, ignoring sparsity (the number of features changed) and plausibility (the likelihood of feature combinations).  \\n\\u2003– Challenges handling categorical features with many levels due to combinatorial explosion.\\n\\n_[Molnar, 2018](https://christophm.github.io/interpretable-ml-book/counterfactual.html)_\\n\\n### 3.2. The Multi-Objective Approach by Dandl et al.\\n\\nDandl et al. (2020) extend the framework by considering four objectives simultaneously:\\n  \\n\\u20031. **Prediction Fidelity (o₁):** The distance between the model output for the counterfactual and the desired output, typically using an L₁ norm.\\n  \\n\\u20032. **Overall Similarity (o₂):** The dissimilarity between the original instance and the counterfactual, measured with the Gower distance, which can handle mixed data types.\\n  \\n\\u20033. **Sparsity (o₃):** The number of features changed (often encoded as an L₀ norm) to achieve the counterfactual outcome, ensuring that explanations remain simple.\\n  \\n\\u20034. **Plausibility (o₄):** How likely it is that the counterfactual instance would occur in the real world (e.g., based on its proximity to observed data points).\\n\\nRather than aggregating these into a single loss function, the method uses multi-objective optimization via the NSGA-II algorithm. NSGA-II evaluates candidates based on a fitness vector (o₁, o₂, o₃, o₄), searches for a set of nondominated (i.e., Pareto-optimal) solutions, and thus provides a diverse set of counterfactual explanations.  \\n \\n**Advantages:**  \\n\\u2003– Balances multiple interpretability criteria simultaneously.  \\n\\u2003– Effectively produces diverse and actionable recommendations.\\n\\n**Limitations:**  \\n\\u2003– Increased computational complexity due to multi-objective search.  \\n\\u2003– Practitioners must choose among multiple valid counterfactuals (the “Rashomon effect”), which can complicate decision-making.\\n\\n_[Dandl et al., 2020](https://christophm.github.io/interpretable-ml-book/counterfactual.html#method-by-dandl-et-al.)_\\n\\n---\\n\\n## 4. Use Cases and Applications\\n\\nCounterfactual explanations have a wide range of applications across different sectors:\\n  \\n- **Finance and Credit Scoring:** They explain why a loan application was rejected and provide concrete guidance (e.g., “increase your income by \\\\$10,000”) for achieving approval.  \\n- **Healthcare:** For diagnostic or treatment recommendation systems, counterfactuals could indicate what slight adjustments in patient inputs might lead to different risk assessments.  \\n- **Real Estate Pricing:** As shown in examples where a prediction model for rent suggests that a 15 m² increase in apartment size or specific features (e.g., installed windows with better insulation) could raise the predicted rent.  \\n\\nThese examples illustrate how counterfactuals empower users with actionable insights, even if some suggestions (like physically expanding an apartment) may not be practically feasible.  \\n \\n_[Lumenova AI Blog](https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/)_\\n\\n---\\n\\n## 5. Strengths and Limitations\\n\\n### 5.1. Strengths\\n\\n- **Clarity and Intuitiveness:**  \\n\\u2002Counterfactual explanations are easy to understand since they directly relate feature changes to output differences.  \\n- **Actionability:**  \\n\\u2002They offer actionable suggestions that can empower users to adjust their inputs to obtain the desired outcome.  \\n- **Model and Data Agnostic:**  \\n\\u2002By relying only on input-output relationships, counterfactual methods can work even when the internal model or full training data are not accessible.  \\n- **Versatility:**  \\n\\u2002Beyond machine learning, the framework applies to any system with defined inputs and outputs, including rule-based systems.\\n\\n### 5.2. Limitations\\n\\n- **Multiplicity of Explanations (Rashomon Effect):**  \\n\\u2002A given instance may have multiple valid counterfactuals, which can be overwhelming and may require criteria for selection or presentation of diverse options.\\n- **Actionability vs. Realism:**  \\n\\u2002Some counterfactuals may suggest changes that are infeasible (e.g., “becoming a decade younger” or “increasing the apartment size by 15 m²”).  \\n- **No Inherent Causality:**  \\n\\u2002Unless integrated with causal models, counterfactual explanations do not imply that the changed features causally influence outcomes in the real world.\\n\\n_[KPMG Insights](https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html)_\\n\\n---\\n\\n## 6. Software Tools and Alternative Approaches\\n\\nSeveral software packages and alternative methods facilitate counterfactual explanation generation:\\n\\n- **Alibi:** A Python library that implements both basic counterfactual methods and prototype-guided extensions.  \\n- **DiCE (Diverse Counterfactual Explanations):** Implements diverse and model-agnostic counterfactual generation using techniques such as determinantal point processes.  \\n- **MACE:** A tool that formulates counterfactual search via satisfiability solvers based on logical formulas.\\n- **Growing Spheres:** An alternative method that iteratively samples points in expanding spheres around the original instance.\\n\\nThese tools provide practitioners with options to generate counterfactuals that best meet the desired criteria in different application settings.\\n\\n_[Molnar, 2018; Mothilal et al., 2020; Karimi et al., 2020]_\\n\\n---\\n\\n## 7. Legal and Ethical Considerations\\n\\nDeploying counterfactual explanations can be beneficial for regulatory compliance (e.g., under GDPR’s requirements for transparency in automated decision-making) and building trust. However, ethical considerations include:\\n\\n- **Fairness and Bias:**  \\n\\u2002Counterfactuals may inadvertently reveal or even suggest biases (e.g., a credit explanation might include changes related to gender).  \\n- **Responsibility in Actionable Guidance:**  \\n\\u2002Users may rely on counterfactual recommendations, so it is crucial to ensure that the suggested changes are feasible and non-discriminatory.\\n\\nLegal compliance and ethical deployment require careful validation of the proposed counterfactuals and their alignment with both domain knowledge and societal norms.\\n\\n_[KPMG Insights](https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html)_\\n\\n---\\n\\n## 8. Future Directions and Emerging Research\\n\\nKey areas for future research include:\\n\\n- **Integrating Causal Inference:**  \\n\\u2002Augmenting counterfactual explanations with causal modeling to ensure that the suggested changes are not only predictive but reflect true cause–effect relationships.\\n- **Improving Computational Efficiency:**  \\n\\u2002Developing methods that reduce the computational burden of multi-objective optimization, particularly for large-scale datasets with complex feature spaces.\\n- **User-Centric Evaluation:**  \\n\\u2002Studying how diverse user groups interpret multiple counterfactual solutions, and developing criteria to prioritize explanations that are most useful and actionable.\\n- **Robustness Against Adversarial Manipulation:**  \\n\\u2002Ensuring that counterfactual explanations remain reliable even when models are subject to adversarial attacks or data shifts.\\n\\n_[Verma et al., 2021](https://arxiv.org/abs/2106.07756)_\\n\\n---\\n\\n## 9. Conclusion\\n\\nCounterfactual explanations provide an accessible bridge between sophisticated machine learning models and human interpretability. By focusing on the minimal yet actionable changes needed to achieve a desired outcome, they offer both justification for decisions and guidance for recourse. The evolution from single-objective methods (e.g., Wachter et al.) to multi-objective frameworks (e.g., Dandl et al.) highlights ongoing efforts to balance prediction fidelity, similarity, sparsity, and plausibility. Despite challenges such as the Rashomon effect and the need for causal grounding, counterfactual explanations remain a crucial component of Explainable AI (XAI), with significant practical, legal, and ethical implications.\\n\\n---\\n\\n## References\\n\\n1. Molnar, C. (n.d.). *Counterfactual Explanations*. Retrieved from [https://christophm.github.io/interpretable-ml-book/counterfactual.html](https://christophm.github.io/interpretable-ml-book/counterfactual.html)\\n2. Dandl, S., Molnar, C., Binder, M., & Bischl, B. (2020). “Multi-Objective Counterfactual Explanations.” In _Parallel Problem Solving from Nature – PPSN XVI_. Springer.\\n3. Wachter, S., Mittelstadt, B., & Russell, C. (2018). “Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.” _Harvard Journal of Law and Technology_.\\n4. Lumenova AI Blog. (2023). *Counterfactual Explanations in Machine Learning*. Retrieved from [https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/](https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/)\\n5. KPMG. (n.d.). *Counterfactual Explanations: The What-Ifs of AI Decision Making*. Retrieved from [https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html](https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html)\\n6. Verma, S., Dickerson, J., & Hines, K. (2021). “Counterfactual Explanations for Machine Learning: Challenges Revisited.” arXiv:2106.07756. Retrieved from [https://arxiv.org/abs/2106.07756](https://arxiv.org/abs/2106.07756)\\n\\n---\\n\\nBy combining insights from academic research, industry implementations, and ethical considerations, counterfactual explanations continue to play a vital role in advancing trust and transparency in AI systems.',\n",
       "  'sources': [{'url': 'https://christophm.github.io/interpretable-ml-book/counterfactual.html',\n",
       "    'title': '15 Counterfactual Explanations – Interpretable Machine Learning',\n",
       "    'description': \"A counterfactual explanation describes a causal situation in the form: “If X had not occurred, Y would not have occurred.” For example: “If I hadn't taken a sip ...\",\n",
       "    'icon': 'https://christophm.github.io/interpretable-ml-book/images/favicon.jpg'},\n",
       "   {'url': 'https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/',\n",
       "    'title': 'Counterfactual Explanations in Machine Learning - Lumenova AI',\n",
       "    'description': 'A counterfactual explanation indicates the smallest change in feature values that can translate to a different outcome. It shows us what should ...',\n",
       "    'icon': 'https://www.lumenova.ai/favicon-32x32.png'},\n",
       "   {'url': 'https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html',\n",
       "    'title': 'Counterfactual Explanations: The What-Ifs of AI Decision Making',\n",
       "    'description': 'A counterfactual explanation involves describing a situation or outcome by considering alternative scenarios or events that did not happen but could have ...',\n",
       "    'icon': 'https://kpmg.com/etc.clientlibs/kpmg/clientlibs/clientlib-site/resources/images/favicons/favicon-32x32.png'},\n",
       "   {'url': 'https://arxiv.org/abs/2106.07756',\n",
       "    'title': '[2106.07756] Counterfactual Explanations for Machine Learning',\n",
       "    'description': 'Counterfactual explanations (CFEs) are an emerging technique under the umbrella of interpretability of machine learning (ML) models.',\n",
       "    'icon': 'https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png'},\n",
       "   {'url': 'https://ml-retrospectives.github.io/neurips2020/camera_ready/5.pdf',\n",
       "    'title': '[PDF] Counterfactual Explanations for Machine Learning: A Review',\n",
       "    'description': 'By definition, counterfactual explanations are applicable to supervised machine learning setup where the desired prediction has not been obtained for a ...',\n",
       "    'icon': ''},\n",
       "   {'url': 'https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html',\n",
       "    'title': 'Counterfactual Explanations: The What-Ifs of AI Decision Making',\n",
       "    'description': \"Counterfactuals help to identify which aspects of the input data are most influential in the model's decisions, aiding in model debugging, fairness analysis and ...\",\n",
       "    'icon': 'https://kpmg.com/etc.clientlibs/kpmg/clientlibs/clientlib-site/resources/images/favicons/favicon-32x32.png'},\n",
       "   {'url': 'https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/',\n",
       "    'title': 'Counterfactual Explanations in Machine Learning - Lumenova AI',\n",
       "    'description': 'A counterfactual explanation indicates the smallest change in feature values that can translate to a different outcome.',\n",
       "    'icon': 'https://www.lumenova.ai/favicon-32x32.png'},\n",
       "   {'url': 'https://link.springer.com/article/10.1007/s11023-023-09637-x',\n",
       "    'title': 'Explainable AI and Causal Understanding: Counterfactual ...',\n",
       "    'description': 'The counterfactual approach to explainable AI (XAI) seeks to provide understanding of AI systems through the provision of counterfactual explanations.',\n",
       "    'icon': 'https://link.springer.com/oscar-static/img/favicons/darwin/android-chrome-192x192-6f081ca7e5.png'},\n",
       "   {'url': 'https://mazzine.medium.com/measuring-counterfactual-explanations-feature-importance-with-counterplots-41359bc85aea',\n",
       "    'title': 'Measuring Counterfactual Explanations Feature Importance with ...',\n",
       "    'description': 'It enables users to understand the reasoning behind AI-based decisions, fostering trust, accountability, and ethical use of AI systems. XAI ...',\n",
       "    'icon': 'https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19'},\n",
       "   {'url': 'https://montrealethics.ai/understanding-the-effect-of-counterfactual-explanations-on-trust-and-reliance-on-ai-for-human-ai-collaborative-clinical-decision-making/',\n",
       "    'title': 'Understanding the Effect of Counterfactual Explanations on Trust ...',\n",
       "    'description': \"This paper explores the effect of counterfactual explanations on users' trust and reliance on AI during a clinical decision-making task.\",\n",
       "    'icon': 'https://montrealethics.ai/wp-content/uploads/2021/01/cropped-NEWlogo-32x32.png'},\n",
       "   {'url': 'https://christophm.github.io/interpretable-ml-book/counterfactual.html',\n",
       "    'title': '15 Counterfactual Explanations – Interpretable Machine Learning',\n",
       "    'description': 'A simple and naive approach to generating counterfactual explanations is searching by trial and error. This approach involves randomly changing feature values ...',\n",
       "    'icon': 'https://christophm.github.io/interpretable-ml-book/images/favicon.jpg'},\n",
       "   {'url': 'https://interpret.ml/DiCE/notebooks/DiCE_getting_started.html',\n",
       "    'title': 'Quick introduction to generating counterfactual explanations using ...',\n",
       "    'description': 'To generate counterfactuals, DiCE implements two kinds of methods: model-agnostic and gradient-based.',\n",
       "    'icon': ''},\n",
       "   {'url': 'https://human-interpretable-ai.github.io/assets/pdf/5_Generative_Models_for_Counte.pdf',\n",
       "    'title': '[PDF] Generative Models for Counterfactual Explanations',\n",
       "    'description': 'Our taxonomy for VAE-based counterfactual generation methods includes optimization methods, which employ optimization of an expression ...',\n",
       "    'icon': ''},\n",
       "   {'url': 'https://link.springer.com/article/10.1007/s10618-022-00831-6',\n",
       "    'title': 'Counterfactual explanations and how to find them: literature review ...',\n",
       "    'description': 'Most of the counterfactual explanation methods are local post-hoc explainers. However, according to the literature in XAI (Adadi et al. 2018; ...',\n",
       "    'icon': 'https://link.springer.com/oscar-static/img/favicons/darwin/android-chrome-192x192-6f081ca7e5.png'},\n",
       "   {'url': 'https://www.sciencedirect.com/science/article/pii/S0020025523014834',\n",
       "    'title': 'On generating trustworthy counterfactual explanations - ScienceDirect',\n",
       "    'description': 'The nineteen algorithms fall into a categorization of six different counterfactual generation strategies: instance-based, constraint-based, genetic-based, ...',\n",
       "    'icon': 'https://sdfestaticassets-us-east-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico'}],\n",
       "  'activities': [{'type': 'search',\n",
       "    'status': 'processing',\n",
       "    'message': 'Generating deeper search queries for \"What are the counterfactual explanations?\"',\n",
       "    'timestamp': '2025-04-26T01:43:24.434Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'search',\n",
       "    'status': 'processing',\n",
       "    'message': 'Starting 3 parallel searches for \"What are the counterfactual explanations?\"',\n",
       "    'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'search',\n",
       "    'status': 'processing',\n",
       "    'message': 'Searching for \"What are counterfactual explanations in machine learning?\" - Goal: To define counterfactual explanations and understand their role in machine learning.',\n",
       "    'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'search',\n",
       "    'status': 'processing',\n",
       "    'message': 'Searching for \"How are counterfactual explanations used in ethical AI?\" - Goal: To explore the application of counterfactual explanations in promoting fairness and transparency in AI systems.',\n",
       "    'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'search',\n",
       "    'status': 'processing',\n",
       "    'message': 'Searching for \"What are the methods for generating counterfactual explanations?\" - Goal: To investigate the various techniques and algorithms used to create counterfactual explanations.',\n",
       "    'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'search',\n",
       "    'status': 'complete',\n",
       "    'message': 'Found 15 new relevant results across 3 parallel queries',\n",
       "    'timestamp': '2025-04-26T01:43:33.490Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'analyze',\n",
       "    'status': 'processing',\n",
       "    'message': 'Analyzing findings and planning next steps',\n",
       "    'timestamp': '2025-04-26T01:43:33.510Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'analyze',\n",
       "    'status': 'complete',\n",
       "    'message': 'Analyzed findings',\n",
       "    'timestamp': '2025-04-26T01:43:42.609Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'synthesis',\n",
       "    'status': 'processing',\n",
       "    'message': 'Preparing final analysis',\n",
       "    'timestamp': '2025-04-26T01:43:42.640Z',\n",
       "    'depth': 1},\n",
       "   {'type': 'synthesis',\n",
       "    'status': 'complete',\n",
       "    'message': 'Research completed',\n",
       "    'timestamp': '2025-04-26T01:44:20.150Z',\n",
       "    'depth': 1}],\n",
       "  'json': None},\n",
       " 'expiresAt': '2025-04-26T07:44:20.000Z',\n",
       " 'currentDepth': 1,\n",
       " 'maxDepth': 5,\n",
       " 'status': 'completed',\n",
       " 'totalUrls': 15,\n",
       " 'activities': [{'type': 'search',\n",
       "   'status': 'processing',\n",
       "   'message': 'Generating deeper search queries for \"What are the counterfactual explanations?\"',\n",
       "   'timestamp': '2025-04-26T01:43:24.434Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'search',\n",
       "   'status': 'processing',\n",
       "   'message': 'Starting 3 parallel searches for \"What are the counterfactual explanations?\"',\n",
       "   'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'search',\n",
       "   'status': 'processing',\n",
       "   'message': 'Searching for \"What are counterfactual explanations in machine learning?\" - Goal: To define counterfactual explanations and understand their role in machine learning.',\n",
       "   'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'search',\n",
       "   'status': 'processing',\n",
       "   'message': 'Searching for \"How are counterfactual explanations used in ethical AI?\" - Goal: To explore the application of counterfactual explanations in promoting fairness and transparency in AI systems.',\n",
       "   'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'search',\n",
       "   'status': 'processing',\n",
       "   'message': 'Searching for \"What are the methods for generating counterfactual explanations?\" - Goal: To investigate the various techniques and algorithms used to create counterfactual explanations.',\n",
       "   'timestamp': '2025-04-26T01:43:27.430Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'search',\n",
       "   'status': 'complete',\n",
       "   'message': 'Found 15 new relevant results across 3 parallel queries',\n",
       "   'timestamp': '2025-04-26T01:43:33.490Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'analyze',\n",
       "   'status': 'processing',\n",
       "   'message': 'Analyzing findings and planning next steps',\n",
       "   'timestamp': '2025-04-26T01:43:33.510Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'analyze',\n",
       "   'status': 'complete',\n",
       "   'message': 'Analyzed findings',\n",
       "   'timestamp': '2025-04-26T01:43:42.609Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'synthesis',\n",
       "   'status': 'processing',\n",
       "   'message': 'Preparing final analysis',\n",
       "   'timestamp': '2025-04-26T01:43:42.640Z',\n",
       "   'depth': 1},\n",
       "  {'type': 'synthesis',\n",
       "   'status': 'complete',\n",
       "   'message': 'Research completed',\n",
       "   'timestamp': '2025-04-26T01:44:20.150Z',\n",
       "   'depth': 1}],\n",
       " 'sources': [{'url': 'https://christophm.github.io/interpretable-ml-book/counterfactual.html',\n",
       "   'title': '15 Counterfactual Explanations – Interpretable Machine Learning',\n",
       "   'description': \"A counterfactual explanation describes a causal situation in the form: “If X had not occurred, Y would not have occurred.” For example: “If I hadn't taken a sip ...\",\n",
       "   'icon': 'https://christophm.github.io/interpretable-ml-book/images/favicon.jpg'},\n",
       "  {'url': 'https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/',\n",
       "   'title': 'Counterfactual Explanations in Machine Learning - Lumenova AI',\n",
       "   'description': 'A counterfactual explanation indicates the smallest change in feature values that can translate to a different outcome. It shows us what should ...',\n",
       "   'icon': 'https://www.lumenova.ai/favicon-32x32.png'},\n",
       "  {'url': 'https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html',\n",
       "   'title': 'Counterfactual Explanations: The What-Ifs of AI Decision Making',\n",
       "   'description': 'A counterfactual explanation involves describing a situation or outcome by considering alternative scenarios or events that did not happen but could have ...',\n",
       "   'icon': 'https://kpmg.com/etc.clientlibs/kpmg/clientlibs/clientlib-site/resources/images/favicons/favicon-32x32.png'},\n",
       "  {'url': 'https://arxiv.org/abs/2106.07756',\n",
       "   'title': '[2106.07756] Counterfactual Explanations for Machine Learning',\n",
       "   'description': 'Counterfactual explanations (CFEs) are an emerging technique under the umbrella of interpretability of machine learning (ML) models.',\n",
       "   'icon': 'https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png'},\n",
       "  {'url': 'https://ml-retrospectives.github.io/neurips2020/camera_ready/5.pdf',\n",
       "   'title': '[PDF] Counterfactual Explanations for Machine Learning: A Review',\n",
       "   'description': 'By definition, counterfactual explanations are applicable to supervised machine learning setup where the desired prediction has not been obtained for a ...',\n",
       "   'icon': ''},\n",
       "  {'url': 'https://kpmg.com/ch/en/insights/artificial-intelligence/counterfactual-explanation.html',\n",
       "   'title': 'Counterfactual Explanations: The What-Ifs of AI Decision Making',\n",
       "   'description': \"Counterfactuals help to identify which aspects of the input data are most influential in the model's decisions, aiding in model debugging, fairness analysis and ...\",\n",
       "   'icon': 'https://kpmg.com/etc.clientlibs/kpmg/clientlibs/clientlib-site/resources/images/favicons/favicon-32x32.png'},\n",
       "  {'url': 'https://www.lumenova.ai/blog/counterfactual-explanations-machine-learning/',\n",
       "   'title': 'Counterfactual Explanations in Machine Learning - Lumenova AI',\n",
       "   'description': 'A counterfactual explanation indicates the smallest change in feature values that can translate to a different outcome.',\n",
       "   'icon': 'https://www.lumenova.ai/favicon-32x32.png'},\n",
       "  {'url': 'https://link.springer.com/article/10.1007/s11023-023-09637-x',\n",
       "   'title': 'Explainable AI and Causal Understanding: Counterfactual ...',\n",
       "   'description': 'The counterfactual approach to explainable AI (XAI) seeks to provide understanding of AI systems through the provision of counterfactual explanations.',\n",
       "   'icon': 'https://link.springer.com/oscar-static/img/favicons/darwin/android-chrome-192x192-6f081ca7e5.png'},\n",
       "  {'url': 'https://mazzine.medium.com/measuring-counterfactual-explanations-feature-importance-with-counterplots-41359bc85aea',\n",
       "   'title': 'Measuring Counterfactual Explanations Feature Importance with ...',\n",
       "   'description': 'It enables users to understand the reasoning behind AI-based decisions, fostering trust, accountability, and ethical use of AI systems. XAI ...',\n",
       "   'icon': 'https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19'},\n",
       "  {'url': 'https://montrealethics.ai/understanding-the-effect-of-counterfactual-explanations-on-trust-and-reliance-on-ai-for-human-ai-collaborative-clinical-decision-making/',\n",
       "   'title': 'Understanding the Effect of Counterfactual Explanations on Trust ...',\n",
       "   'description': \"This paper explores the effect of counterfactual explanations on users' trust and reliance on AI during a clinical decision-making task.\",\n",
       "   'icon': 'https://montrealethics.ai/wp-content/uploads/2021/01/cropped-NEWlogo-32x32.png'},\n",
       "  {'url': 'https://christophm.github.io/interpretable-ml-book/counterfactual.html',\n",
       "   'title': '15 Counterfactual Explanations – Interpretable Machine Learning',\n",
       "   'description': 'A simple and naive approach to generating counterfactual explanations is searching by trial and error. This approach involves randomly changing feature values ...',\n",
       "   'icon': 'https://christophm.github.io/interpretable-ml-book/images/favicon.jpg'},\n",
       "  {'url': 'https://interpret.ml/DiCE/notebooks/DiCE_getting_started.html',\n",
       "   'title': 'Quick introduction to generating counterfactual explanations using ...',\n",
       "   'description': 'To generate counterfactuals, DiCE implements two kinds of methods: model-agnostic and gradient-based.',\n",
       "   'icon': ''},\n",
       "  {'url': 'https://human-interpretable-ai.github.io/assets/pdf/5_Generative_Models_for_Counte.pdf',\n",
       "   'title': '[PDF] Generative Models for Counterfactual Explanations',\n",
       "   'description': 'Our taxonomy for VAE-based counterfactual generation methods includes optimization methods, which employ optimization of an expression ...',\n",
       "   'icon': ''},\n",
       "  {'url': 'https://link.springer.com/article/10.1007/s10618-022-00831-6',\n",
       "   'title': 'Counterfactual explanations and how to find them: literature review ...',\n",
       "   'description': 'Most of the counterfactual explanation methods are local post-hoc explainers. However, according to the literature in XAI (Adadi et al. 2018; ...',\n",
       "   'icon': 'https://link.springer.com/oscar-static/img/favicons/darwin/android-chrome-192x192-6f081ca7e5.png'},\n",
       "  {'url': 'https://www.sciencedirect.com/science/article/pii/S0020025523014834',\n",
       "   'title': 'On generating trustworthy counterfactual explanations - ScienceDirect',\n",
       "   'description': 'The nineteen algorithms fall into a categorization of six different counterfactual generation strategies: instance-based, constraint-based, genetic-based, ...',\n",
       "   'icon': 'https://sdfestaticassets-us-east-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
