{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "from openai_hackathon_wait.rag import RAG\n",
    "from openai_hackathon_wait.create_context import create_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_CONTENT = \"\"\"\n",
    "# Abstract\n",
    "\n",
    "We present PPCEF, a novel method for generating prob-\n",
    "abilistically plausible counterfactual explanations (CFs). PPCEF ad-\n",
    "vances beyond existing methods by combining a probabilistic formula-\n",
    "tion that leverages the data distribution with the optimization of plausi-\n",
    "bility within a unified framework. Compared to reference approaches,\n",
    "our method enforces plausibility by directly optimizing the explicit\n",
    "density function without assuming a particular family of parametrized\n",
    "distributions. This ensures CFs are not only valid (i.e., achieve class\n",
    "change) but also align with the underlying data’s probability density.\n",
    "For that purpose, our approach leverages normalizing flows as power-\n",
    "ful density estimators to capture the complex high-dimensional data\n",
    "distribution. Furthermore, we introduce a novel loss function that bal-\n",
    "ances the trade-off between achieving class change and maintaining\n",
    "closeness to the original instance while also incorporating a proba-\n",
    "bilistic plausibility term. PPCEF’s unconstrained formulation allows\n",
    "for an efficient gradient-based optimization with batch processing,\n",
    "leading to orders of magnitude faster computation compared to prior\n",
    "methods. Moreover, the unconstrained formulation of PPCEF allows\n",
    "for the seamless integration of future constraints tailored to specific\n",
    "counterfactual properties. Finally, extensive evaluations demonstrate\n",
    "PPCEF’s superiority in generating high-quality, probabilistically plau-\n",
    "sible counterfactual explanations in high-dimensional tabular settings.\n",
    "\n",
    "# Keywords\n",
    "Counterfactual Explanations, Probabilistic Plausibility, Normalizing Flows, Explainable AI (XAI)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-26 09:59:40.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mMax results: 5\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:40.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSort by: relevance\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:40.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mStarting arXiv search for: Counterfactual Explanations, Probabilistic Plausibility, Normalizing Flows, Explainable AI (XAI)\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:43.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.api.utils.get_article_keywords\u001b[0m:\u001b[36mget_article_keywords\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mArticle keywords response: keywords=['Counterfactual Explanations', 'Probabilistic Plausibility', 'Normalizing Flows', 'Explainable AI', 'XAI', 'Causal Inference', 'Machine Learning Interpretability', 'Causal Models', 'Data-Driven Explanations', 'Generative Models', 'Bayesian Inference', 'Statistical Plausibility', 'Model Interpretability', 'Deep Learning Explanations', 'Counterfactual Reasoning', 'Probabilistic Graphical Models', 'Feature Importance', 'Adversarial Examples', 'Causal Relationships', 'Explainability in AI', 'AI Transparency', 'Decision Making in AI', 'Ethics in AI', 'Model Evaluation', 'Uncertainty Quantification', 'Data Visualization Techniques', 'Algorithmic Fairness', 'Human-AI Interaction', 'Causal Discovery', 'Representation Learning']\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:43.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mExtracted keywords: ['Model Evaluation', 'Causal Discovery', 'Adversarial Examples', 'Algorithmic Fairness', 'AI Transparency', 'Ethics in AI', 'Data Visualization Techniques', 'Normalizing Flows', 'Model Interpretability', 'Feature Importance', 'Probabilistic Graphical Models', 'Deep Learning Explanations', 'Human-AI Interaction', 'Data-Driven Explanations', 'Representation Learning', 'XAI', 'Counterfactual Explanations', 'Causal Inference', 'Machine Learning Interpretability', 'Causal Relationships', 'Explainability in AI', 'Causal Models', 'Generative Models', 'Counterfactual Reasoning', 'Bayesian Inference', 'Decision Making in AI', 'Statistical Plausibility', 'Uncertainty Quantification', 'Explainable AI', 'Probabilistic Plausibility']\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:49.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.api.utils.get_article_keywords\u001b[0m:\u001b[36mget_expanded_keywords\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mExpanded keywords response: keywords=['Model Assessment', 'Causal Inference Techniques', 'Adversarial Attacks', 'Fairness in Algorithms', 'AI Accountability', 'Ethical AI Practices', 'Data Visualization Methods', 'Normalizing Flow Models', 'Model Explainability', 'Feature Attribution', 'Graphical Models in Probabilistic Reasoning', 'Deep Learning Interpretability', 'Human-Machine Interaction', 'Data-Driven Insights', 'Representation Learning Techniques', 'Explainable Artificial Intelligence (XAI)', 'Counterfactual Analysis', 'Causal Reasoning', 'Machine Learning Transparency', 'Causal Relationships in AI', 'Explainability Frameworks', 'Causal Modeling Approaches', 'Generative Adversarial Models', 'Counterfactual Analysis in AI', 'Bayesian Reasoning', 'AI Decision-Making Processes', 'Statistical Validity', 'Uncertainty Analysis in AI', 'Explainable Machine Learning', 'Probabilistic Reasoning in AI']\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:49.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mExpanded keywords: ['Model Evaluation', 'Causal Discovery', 'Explainable Machine Learning', 'Adversarial Examples', 'Generative Adversarial Models', 'Causal Relationships in AI', 'Explainability Frameworks', 'Algorithmic Fairness', 'Model Assessment', 'AI Transparency', 'Ethics in AI', 'Data Visualization Techniques', 'Graphical Models in Probabilistic Reasoning', 'Bayesian Reasoning', 'Uncertainty Analysis in AI', 'Causal Modeling Approaches', 'Statistical Validity', 'Normalizing Flows', 'Probabilistic Reasoning in AI', 'Model Interpretability', 'Causal Inference Techniques', 'Counterfactual Analysis in AI', 'Feature Importance', 'Probabilistic Graphical Models', 'Counterfactual Analysis', 'Deep Learning Explanations', 'Human-AI Interaction', 'Data-Driven Explanations', 'Representation Learning', 'XAI', 'Counterfactual Explanations', 'Causal Inference', 'AI Accountability', 'Fairness in Algorithms', 'Normalizing Flow Models', 'Machine Learning Transparency', 'Human-Machine Interaction', 'AI Decision-Making Processes', 'Machine Learning Interpretability', 'Causal Relationships', 'Explainability in AI', 'Causal Models', 'Data Visualization Methods', 'Feature Attribution', 'Generative Models', 'Counterfactual Reasoning', 'Ethical AI Practices', 'Bayesian Inference', 'Causal Reasoning', 'Representation Learning Techniques', 'Data-Driven Insights', 'Decision Making in AI', 'Deep Learning Interpretability', 'Statistical Plausibility', 'Uncertainty Quantification', 'Model Explainability', 'Adversarial Attacks', 'Explainable AI', 'Probabilistic Plausibility', 'Explainable Artificial Intelligence (XAI)']\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:54.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mFound 5 papers urls on arXiv matching the query\u001b[0m\n",
      "\u001b[32m2025-04-26 09:59:54.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mopenai_hackathon_wait.tools.arxiv_tool\u001b[0m:\u001b[36marxiv_search\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mPapers: ['http://arxiv.org/pdf/2503.18185v1', 'http://arxiv.org/pdf/2503.18185v1', 'http://arxiv.org/pdf/2503.18185v1', 'http://arxiv.org/pdf/2503.18185v1', 'http://arxiv.org/pdf/2503.18185v1']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[search] Generating deeper search queries for \"\n",
      "# Abstract\n",
      "\n",
      "We present PPCEF, a novel method for generating prob-\n",
      "abilistically plausible counterfactual explanations (CFs). PPCEF ad-\n",
      "vances beyond existing methods by combining a probabilistic formula-\n",
      "tion that leverages the data distribution with the optimization of plausi-\n",
      "bility within a unified framework. Compared to reference approaches,\n",
      "our method enforces plausibility by directly optimizing the explicit\n",
      "density function without assuming a particular family of parametrized\n",
      "distributions. This ensures CFs are not only valid (i.e., achieve class\n",
      "change) but also align with the underlying data’s probability density.\n",
      "For that purpose, our approach leverages normalizing flows as power-\n",
      "ful density estimators to capture the complex high-dimensional data\n",
      "distribution. Furthermore, we introduce a novel loss function that bal-\n",
      "ances the trade-off between achieving class change and maintaining\n",
      "closeness to the original instance while also incorporating a proba-\n",
      "bilistic plausibility term. PPCEF’s unconstrained formulation allows\n",
      "for an efficient gradient-based optimization with batch processing,\n",
      "leading to orders of magnitude faster computation compared to prior\n",
      "methods. Moreover, the unconstrained formulation of PPCEF allows\n",
      "for the seamless integration of future constraints tailored to specific\n",
      "counterfactual properties. Finally, extensive evaluations demonstrate\n",
      "PPCEF’s superiority in generating high-quality, probabilistically plau-\n",
      "sible counterfactual explanations in high-dimensional tabular settings.\n",
      "\n",
      "# Keywords\n",
      "Counterfactual Explanations, Probabilistic Plausibility, Normalizing Flows, Explainable AI (XAI)\n",
      "\"\n",
      "[search] Starting 3 parallel searches for \"\n",
      "# Abstract\n",
      "\n",
      "We present PPCEF, a novel method for generating prob-\n",
      "abilistically plausible counterfactual explanations (CFs). PPCEF ad-\n",
      "vances beyond existing methods by combining a probabilistic formula-\n",
      "tion that leverages the data distribution with the optimization of plausi-\n",
      "bility within a unified framework. Compared to reference approaches,\n",
      "our method enforces plausibility by directly optimizing the explicit\n",
      "density function without assuming a particular family of parametrized\n",
      "distributions. This ensures CFs are not only valid (i.e., achieve class\n",
      "change) but also align with the underlying data’s probability density.\n",
      "For that purpose, our approach leverages normalizing flows as power-\n",
      "ful density estimators to capture the complex high-dimensional data\n",
      "distribution. Furthermore, we introduce a novel loss function that bal-\n",
      "ances the trade-off between achieving class change and maintaining\n",
      "closeness to the original instance while also incorporating a proba-\n",
      "bilistic plausibility term. PPCEF’s unconstrained formulation allows\n",
      "for an efficient gradient-based optimization with batch processing,\n",
      "leading to orders of magnitude faster computation compared to prior\n",
      "methods. Moreover, the unconstrained formulation of PPCEF allows\n",
      "for the seamless integration of future constraints tailored to specific\n",
      "counterfactual properties. Finally, extensive evaluations demonstrate\n",
      "PPCEF’s superiority in generating high-quality, probabilistically plau-\n",
      "sible counterfactual explanations in high-dimensional tabular settings.\n",
      "\n",
      "# Keywords\n",
      "Counterfactual Explanations, Probabilistic Plausibility, Normalizing Flows, Explainable AI (XAI)\n",
      "\"\n",
      "[search] Searching for \"Probabilistically plausible counterfactual explanations in AI\" - Goal: To understand the basic concept of probabilistically plausible counterfactual explanations and their significance in explainable AI.\n",
      "[search] Searching for \"Normalizing flows in generating counterfactual explanations\" - Goal: To explore how normalizing flows are utilized as density estimators in the context of generating counterfactual explanations.\n",
      "[search] Searching for \"Loss functions for optimizing counterfactual explanations\" - Goal: To investigate different loss functions used in the optimization of counterfactual explanations, focusing on balancing class change and plausibility.\n",
      "[search] Found 15 new relevant results across 3 parallel queries\n",
      "[analyze] Analyzing findings and planning next steps\n",
      "[analyze] Analyzed findings\n",
      "[search] Generating deeper search queries for \"Limited exploration of the integration of PPCEF with other machine learning models beyond those tested (Logistic Regression, MLP, NODE).\"\n",
      "[search] Starting 3 parallel searches for \"Limited exploration of the integration of PPCEF with other machine learning models beyond those tested (Logistic Regression, MLP, NODE).\"\n",
      "[search] Searching for \"Integration of PPCEF with advanced machine learning models\" - Goal: To explore how Probabilistically Plausible Counterfactual Explanations (PPCEF) can be integrated with various advanced machine learning models, focusing on methodologies and frameworks.\n",
      "[search] Searching for \"Real-world applications of PPCEF in AI systems\" - Goal: To investigate practical applications of PPCEF in real-world AI systems, including case studies and industry implementations.\n",
      "[search] Searching for \"Comparative analysis of PPCEF and traditional counterfactual explanation methods\" - Goal: To analyze the differences and advantages of PPCEF over traditional counterfactual explanation methods, highlighting performance metrics and use cases.\n",
      "[search] Found 15 new relevant results across 3 parallel queries\n",
      "[analyze] Analyzing findings and planning next steps\n",
      "[analyze] Analyzed findings\n",
      "[synthesis] Preparing final analysis\n"
     ]
    }
   ],
   "source": [
    "rag = await create_context(client, \"test\", PAPER_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFileSearchToolCall(id='fs_680c8f6c769481929f09caa3f2a7ba3405cd05c24bad628c', queries=['What is counterfactual explanation?'], status='completed', type='file_search_call', results=None),\n",
       " ResponseOutputMessage(id='msg_680c8f6ea02c8192936c48ee667d3f0c05cd05c24bad628c', content=[ResponseOutputText(annotations=[AnnotationFileCitation(file_id='file-UqFoQV99iitDTu59hC8nY1', index=427, type='file_citation', filename='temp.txt'), AnnotationFileCitation(file_id='file-UqFoQV99iitDTu59hC8nY1', index=800, type='file_citation', filename='temp.txt')], text='Counterfactual explanations aim to answer \"what if\" questions by identifying the minimal changes needed to an input so that a machine learning model\\'s prediction shifts to a desired outcome. They are crucial in applications like credit scoring and medical diagnosis, where it is important for the explanations to be not only valid (achieving the desired prediction) but also realistic and plausible within the data distribution.\\n\\nThese explanations typically evaluate:\\n- **Validity:** Whether the counterfactual alters the prediction as intended.\\n- **Proximity:** How close the generated counterfactual is to the original input.\\n- **Sparsity and Actionability:** The number and nature of changes proposed.\\n- **Plausibility:** Whether the generated instance aligns realistically with the training data. \\n\\nThis framework advances transparency in AI systems, making it easier to understand decisions made by complex models .', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rag[0].ask_question(\"what is countefactual explanation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG class checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()\n",
    "rag = RAG(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "await rag.create_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "await rag.upload_file(\"../data/test_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFileSearchToolCall(id='fs_680c204bc1b08192b26b03f5e07d71e7027745d365d9653f', queries=['what is life?', 'definition of life', 'meaning of life'], status='completed', type='file_search_call', results=None),\n",
       " ResponseOutputMessage(id='msg_680c204e11ec8192851bf90008fe1d2d027745d365d9653f', content=[ResponseOutputText(annotations=[], text='The files you uploaded do not directly provide a definition or explanation of \"life.\" However, if you\\'re seeking general perspectives on what life is, it can be described in various ways:\\n\\n1. **Biological Definition**: Life is typically characterized by biological processes such as growth, reproduction, responsiveness to stimuli, and metabolism.\\n\\n2. **Philosophical Perspective**: Philosophically, life can encompass the existential questions about existence, meaning, and purpose, often explored in the realms of ethics, symbolism, and personal experience.\\n\\n3. **Spiritual Context**: In many spiritual views, life is seen as a journey or a stage of existence that goes beyond mere biological factors, involving consciousness and a connection to something greater.\\n\\nIf you want a more specific aspect or a particular context regarding \"life,\" feel free to clarify!', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rag.ask_question(\"what is life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "await rag.delete_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
