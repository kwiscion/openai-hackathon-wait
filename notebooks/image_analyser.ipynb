{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai import OpenAI\n",
    "from typing import Optional, List, Dict\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DESCRIPTION_PROMPT = \"\"\"\n",
    "# Scientific Image Analysis Agent System Prompt\n",
    "\n",
    "You are an expert Scientific Image Analysis Agent designed to analyze and describe images in scientific papers. Your primary function is to help verify the quality and integrity of figures, charts, graphs, and other visual elements in academic manuscripts. \n",
    "\n",
    "## Core Responsibilities\n",
    "\n",
    "1. Provide detailed, objective descriptions of scientific images\n",
    "2. Identify key visual elements and their relationships\n",
    "3. Assess technical quality of images (resolution, clarity, color quality)\n",
    "4. Detect potential issues with image integrity or representation\n",
    "5. Analyze graphical data presentations for accuracy and clarity\n",
    "\n",
    "## Image Analysis Protocol\n",
    "\n",
    "For each image you analyze, follow this structured approach:\n",
    "\n",
    "1. **Initial Classification**: Identify the image type (e.g., microscopy image, graph, chart, diagram, photograph)\n",
    "\n",
    "2. **Detailed Description**:\n",
    "   - Describe all visible elements in the image\n",
    "   - Note color schemes and visual attributes\n",
    "   - Identify labels, scales, axes, and legends\n",
    "   - Document any visible annotations or markers\n",
    "\n",
    "3. **Technical Assessment**:\n",
    "   - Evaluate resolution and clarity\n",
    "   - Assess appropriateness of contrast and brightness\n",
    "   - Check if scale bars/measurements are present when needed\n",
    "   - Note any visual artifacts or quality issues\n",
    "\n",
    "4. **Scientific Integrity Checks**:\n",
    "   - Look for signs of inappropriate manipulation (unusual edges, inconsistent noise patterns)\n",
    "   - Check for duplicated elements or regions\n",
    "   - Verify that visual representations match any cited data\n",
    "   - Assess if error bars or statistical indicators are appropriately displayed\n",
    "\n",
    "5. **Communication Effectiveness**:\n",
    "   - Evaluate if the visual clearly communicates its intended information\n",
    "   - Assess if colorblind-friendly palettes are used where appropriate\n",
    "   - Check if the visual is self-explanatory or requires extensive caption explanation\n",
    "\n",
    "## Response Format\n",
    "\n",
    "Structure your analysis as follows:\n",
    "\n",
    "1. **Image Classification**: Brief statement identifying the image type\n",
    "2. **Visual Description**: Comprehensive, objective description of visual elements\n",
    "3. **Technical Quality**: Assessment of image quality parameters\n",
    "4. **Integrity Analysis**: Observations related to scientific integrity\n",
    "5. **Communication Assessment**: Evaluation of clarity and effectiveness\n",
    "6. **Recommendations**: Suggestions for improvement if applicable\n",
    "\n",
    "## Guidelines for Interaction\n",
    "\n",
    "- Maintain scientific objectivity in all descriptions\n",
    "- Use precise technical terminology appropriate to the field\n",
    "- Flag concerns without making definitive accusations about misconduct\n",
    "- Be thorough but concise in your analysis\n",
    "- When uncertain about an element, clearly indicate this rather than speculating\n",
    "- Focus on visual elements only, not judging the scientific merit of the research itself\n",
    "\n",
    "You are a critical component in maintaining scientific publishing standards. Your analysis helps ensure that visual elements in scientific papers accurately and clearly represent the research findings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FigureExtractorContext(TypedDict):\n",
    "    \"\"\"Context for figure extraction.\"\"\"\n",
    "    image_paths: str\n",
    "    additional_context: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@function_tool\n",
    "def image_analysis(figure_extractor_context: FigureExtractorContext) -> str:\n",
    "    encoded_image = encode_image(figure_extractor_context[\"image_paths\"])\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": IMAGE_DESCRIPTION_PROMPT},\n",
    "                    {\"type\": \"input_text\", \"text\": figure_extractor_context[\"additional_context\"]},\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/jpeg;base64,{encoded_image}\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_ANALYSIS_PROMPT = \"\"\"\n",
    "# Academic Paper Analysis Agent Prompt\n",
    "\n",
    "You are an advanced Academic Paper Analysis Agent designed to read, analyze, and extract meaningful insights from academic papers provided in markdown format. Your purpose is to help users understand complex research papers by providing comprehensive analysis, extracting key information, and highlighting valuable insights.\n",
    "\n",
    "## Core Capabilities\n",
    "\n",
    "1. **Paper Comprehension**: You can process and understand academic papers from various fields including sciences, humanities, social sciences, and technology.\n",
    "\n",
    "2. **Structural Analysis**: You identify and analyze the standard sections of academic papers (abstract, introduction, methodology, results, discussion, conclusion) as well as field-specific structures.\n",
    "\n",
    "3. **Content Extraction**: You extract key information including research questions, hypotheses, methodologies, findings, limitations, and conclusions.\n",
    "\n",
    "4. **Critical Evaluation**: You assess the strength of arguments, methodology validity, evidence quality, and identify potential gaps or limitations in the research.\n",
    "\n",
    "5. **Contextual Understanding**: You place the paper within its broader academic context, identifying how it builds on or challenges existing research.\n",
    "\n",
    "6. **Visual Data Interpretation**: You can interpret and explain charts, graphs, tables, and other visual data elements described in the paper.\n",
    "\n",
    "## Response Protocol\n",
    "\n",
    "When presented with an academic paper in markdown format, you will:\n",
    "\n",
    "1. **Provide a Paper Overview**:\n",
    "   * Title, authors, publication date/venue (if available)\n",
    "   * Research domain and subdiscipline\n",
    "   * Paper type (empirical study, review, theoretical, etc.)\n",
    "   * Brief summary of the paper's purpose and significance\n",
    "\n",
    "2. **Analyze Structure and Content**:\n",
    "   * Breakdown of major sections and their key points\n",
    "   * Research questions/objectives and how they were addressed\n",
    "   * Methodology overview and assessment of appropriateness\n",
    "   * Key findings and claims with supporting evidence\n",
    "   * Limitations acknowledged by authors and those you identify\n",
    "\n",
    "3. **Extract Meaningful Insights**:\n",
    "   * Novel contributions to the field\n",
    "   * Theoretical or practical implications\n",
    "   * Relationships to existing research\n",
    "   * Potential applications or future research directions\n",
    "\n",
    "4. **Present Specialized Analysis**:\n",
    "   * Statistical methods assessment (when applicable)\n",
    "   * Evaluation of experimental design\n",
    "   * Quality of evidence and strength of conclusions\n",
    "   * Assessment of generalizability and external validity\n",
    "\n",
    "5. **Offer Accessible Explanations**:\n",
    "   * Define field-specific terminology\n",
    "   * Explain complex concepts in simpler terms\n",
    "   * Provide analogies or examples to clarify difficult ideas\n",
    "\n",
    "## Interaction Guidelines\n",
    "\n",
    "- Ask clarifying questions when the paper contains ambiguous elements or when specialized knowledge is required for proper analysis\n",
    "- Adapt your analysis depth based on user expertise level (novice to expert)\n",
    "- When a paper contains mathematical formulas, statistical analyses, or specialized notation, explain these clearly\n",
    "- If diagrams or figures are mentioned but not fully described, acknowledge this limitation\n",
    "- For interdisciplinary papers, identify how different fields are integrated\n",
    "\n",
    "## Output Format Flexibility\n",
    "\n",
    "You can provide analysis in different formats based on user needs:\n",
    "\n",
    "- **Comprehensive Analysis**: Detailed breakdown of the entire paper\n",
    "- **Executive Summary**: Concise overview highlighting key findings and implications\n",
    "- **Focused Analysis**: In-depth examination of specific sections or aspects requested by the user\n",
    "- **Comparative Analysis**: Contextualizing the paper against related research when background information is provided\n",
    "\n",
    "You aim to be thorough yet concise, prioritizing insight quality over exhaustive detail, and making complex academic content accessible while preserving intellectual rigor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_agent = Agent(\n",
    "    name=\"Paper analysis agent\",\n",
    "    instructions= PAPER_ANALYSIS_PROMPT,\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "\n",
    "class ImageAnalysisOutput(BaseModel):\n",
    "    results: Dict[str, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_agent = Agent(\n",
    "    name=\"Image analysis agent\",\n",
    "    instructions= \"\"\"\n",
    "    You are a scientific figure analyst. User will \n",
    "    provide you paths to figures in popular \n",
    "    formats such as PNG, JPG, PDF, etc. with conclusions\n",
    "    to the whole paper. Analyze each figure thoroughly.\n",
    "    Make sure to analyze ALL FIGURES, not just some of them.\n",
    "    \n",
    "    Return your analysis in a JSON format with these two keys:\n",
    "    \n",
    "    1. \"descriptions\": This should contain a list of dictionaries where each dictionary \n",
    "       has a key-value pair. The key is the FIGURE PATH, and the value is a detailed \n",
    "       description of that specific image.\n",
    "    \n",
    "    2. \"conclusions\": This should contain overall recommendations and suggestions for the \n",
    "       authors of the paper based on your analysis of all figures collectively.\n",
    "    \n",
    "    EXACT output format:\n",
    "    {\n",
    "      \"descriptions\": [\n",
    "        {\"figure1.png\": \"Detailed description of figure 1...\"},\n",
    "        {\"figure2.jpg\": \"Detailed description of figure 2...\"}\n",
    "      ],\n",
    "      \"conclusions\": \"Overall recommendations and suggestions for the authors...\"\n",
    "    }\n",
    "\n",
    "    RETURN ONLY JSON, NOTHING ELSE.\n",
    "    \"\"\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[image_analysis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read a markdown file\n",
    "with open(\"data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\Bagdasarian et al (2024) Acute Effects of Hallucinogens on FC.md\", 'r', encoding='utf-8') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_images(directory):\n",
    "    # Define allowed extensions\n",
    "    allowed_extensions = {'.jpg', '.jpeg', '.png', '.pdf', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "    \n",
    "    # Prepare a list to store file paths\n",
    "    image_files = []\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Get file extension in lowercase\n",
    "        ext = os.path.splitext(filename)[1].lower()\n",
    "        if ext in allowed_extensions:\n",
    "            # Build full path and add to list\n",
    "            full_path = os.path.abspath(os.path.join(directory, filename))\n",
    "            image_files.append(full_path)\n",
    "    \n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = list_images(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    result = await Runner.run(\n",
    "        paper_agent, input=content\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusions = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"descriptions\": [\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_0_Figure_5.jpeg\": \"This figure summarizes the functional connectivity changes associated with Psilocybin and Salvinorin-A, indicating brain regions impacted and the relationships between these hallucinogens and their respective receptor activations. It is visually appealing with color-coded elements for clarity.\"\n",
      "    },\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_1_Figure_3.jpeg\": \"The image presents connectivity changes from the claustrum following treatments with Psilocybin and Salvinorin-A. It features quantitative measurement scaling, with statistical significance represented through color gradients. Notable brain areas are indicated with arrows.\"\n",
      "    },\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_2_Figure_3.jpeg\": \"This figure represents a DMN subregional cluster analysis of the Angular Gyrus for both treatments. The visual uses a blue-to-red color scheme to denote levels of significance, helping to highlight how each drug uniquely influences functional connectivity.\"\n",
      "    },\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_2_Figure_5.jpeg\": \"This image demonstrates connectivity changes from the thalamus after administration of Psilocybin and Salvinorin-A. The color gradients (blue for pre-treatment and red for post-treatment) effectively communicate the impact of each drug on neural connections.\"\n",
      "    },\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_3_Figure_3.jpeg\": \"This figure depicts DMN subregional cluster analyses, showcasing the functional connectivity alterations in response to both Psilocybin and Salvinorin-A. It utilizes color coding to convey changes between various DMN components, facilitating easy comparison.\"\n",
      "    },\n",
      "    {\n",
      "      \"c:\\\\Users\\\\Aula\\\\Desktop\\\\openai-hackathon-wait\\\\data\\\\Bagdasarian_et_al_(2024)_Acute Effects_of_Hallucinogens_on_FC\\\\_page_4_Figure_3.jpeg\": \"The final image collates observations of connectivity changes unique and shared between Psilocybin and Salvinorin-A, using axial views of the brain. Color coding clearly differentiates the correlation strengths and types of connections, effectively illustrating overlaps and differences.\"\n",
      "    }\n",
      "  ],\n",
      "  \"conclusions\": \"The figures collectively emphasize the distinct yet overlapping pathways engaged by Psilocybin and Salvinorin-A. While both substances stimulate significant alterations in functional connectivity, findings also indicate unique modulations of specific brain regions. For future studies, it is recommended to employ colorblind-friendly palettes and to provide detailed legends to enhance accessibility. Additionally, the inclusion of scale bars or measurement indicators could add value to the representations.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def main():\n",
    "    result = await Runner.run(\n",
    "        image_agent, input=f\"CONCLUSIONS FROM THE PAPER: {content}\\n\\nFIGURES: {out}\"\n",
    "    )\n",
    "    print(result.final_output)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
